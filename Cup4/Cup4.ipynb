{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>DataLab Cup 4: Recommender Systems</center>\n",
    "<center>Shan-Hung Wu & DataLab</center>\n",
    "<center>Fall 2023</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platform: [Kaggle](https://www.kaggle.com/t/b06e248a3827434f80c4fdc6009d5fe0)\n",
    "\n",
    "Please download the dataset and the environment source code from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this competition, your goal is to design a recommender system that suggests news articles to users. The performance of your recommender system will be assessed using a simulation environment.\n",
    "\n",
    "At each timestep, the simulation environment randomly selects an active user with a given `user_id`. Once you receive this `user_id`, your recommender system must generate a slate **(a list of 5 distinct `item_ids` to recommend to the current user)** and pass it to the environment. The environment then uses its internal information to determine which item the user will choose from the recommended list (with some degree of stochasticity) or decide not to choose any item due to a lack of interest.\n",
    "\n",
    "Each user has a latent patience value (invisible to your recommender system), which slightly increases when an item is chosen and drastically decreases when no item is chosen in each round. If a user's patience drops below 0 or the user runs out of the time budget (2000 timesteps), the user leaves the environment. The chosen `item_id` (or `-1` if no item is chosen) and whether the current user stays (`True`) or leaves (`False`) are returned as the result of recommending a slate of items. A new user (if any) will be randomly selected for recommendations in the next timestep after the response of the current user is generated.\n",
    "\n",
    "Your recommender system should continue recommending items to the current user at each timestep as long as there are still active users in the environment. The simulation process terminates after all users have left the system.\n",
    "\n",
    "**Your goal is to maximize the session length of each user.** The session length is defined as the number of timesteps a user interacts with your recommender system before leaving the environment. The calculated session length score, normalized to the range of 0 ~ 1, will be provided by the simulation environment after the completion of the simulation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from evaluation.environment import TrainingEnvironment, TestingEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official hyperparameters for this competition (do not modify)\n",
    "N_TRAIN_USERS = 1000\n",
    "N_TEST_USERS = 2000\n",
    "N_ITEMS = 209527\n",
    "HORIZON = 2000\n",
    "TEST_EPISODES = 5\n",
    "SLATE_SIZE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "In this competition, we won't provide a substantial user-item interaction dataset. Instead, limited information (3 items per user) on historical interactions will be available. To train your recommender system effectively, you need to employ a recommender policy to interact with the training environment and collect additional interaction data.\n",
    "\n",
    "We will introduce the side-information datasets provided in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "USER_DATA = os.path.join('dataset', 'user_data.json')\n",
    "ITEM_DATA = os.path.join('dataset', 'item_data.json')\n",
    "\n",
    "# Output file path\n",
    "OUTPUT_PATH = os.path.join('output', 'output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Data\n",
    "\n",
    "In the **training environment**, there are a total of **1000 users** identified by IDs ranging from 0 to 999. For the **testing environment**, there are **2000 users** with IDs ranging from 0 to 1999. The **testing environment includes the same 1000 users found in the training environment** (user 0 to user 999), and an additional 1000 new users (user 1000 to user 1999) are introduced.\n",
    "\n",
    "For all 2000 users, we provide you with the **past 3 clicked item IDs of each user**. Let's examine the user dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>history</th>\n",
       "      <th>non_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[65272, 13353, 62006, 42558]</td>\n",
       "      <td>[104449, 190467, 157700, 28682, 167947, 118802...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[170112, 159877, 146057, 141458, 197398, 15861...</td>\n",
       "      <td>[57354, 151563, 133138, 135188, 96277, 67608, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[67551, 85247, 33714]</td>\n",
       "      <td>[141318, 190479, 159759, 194577, 208913, 10259...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[116097, 192703, 123460, 172366, 199798, 13973...</td>\n",
       "      <td>[112647, 14345, 129036, 190479, 159782, 176167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[166371, 203817, 154254, 201649, 68756, 135289...</td>\n",
       "      <td>[122882, 108565, 110620, 63533, 77871, 54, 778...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>[95090, 131393, 130239]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>[2360, 147130, 8145]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>[99794, 138694, 157888]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>[55561, 60372, 51442]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>[125409, 77906, 124792]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                            history  \\\n",
       "0           0                       [65272, 13353, 62006, 42558]   \n",
       "1           1  [170112, 159877, 146057, 141458, 197398, 15861...   \n",
       "2           2                              [67551, 85247, 33714]   \n",
       "3           3  [116097, 192703, 123460, 172366, 199798, 13973...   \n",
       "4           4  [166371, 203817, 154254, 201649, 68756, 135289...   \n",
       "...       ...                                                ...   \n",
       "1995     1995                            [95090, 131393, 130239]   \n",
       "1996     1996                               [2360, 147130, 8145]   \n",
       "1997     1997                            [99794, 138694, 157888]   \n",
       "1998     1998                              [55561, 60372, 51442]   \n",
       "1999     1999                            [125409, 77906, 124792]   \n",
       "\n",
       "                                              non_click  \n",
       "0     [104449, 190467, 157700, 28682, 167947, 118802...  \n",
       "1     [57354, 151563, 133138, 135188, 96277, 67608, ...  \n",
       "2     [141318, 190479, 159759, 194577, 208913, 10259...  \n",
       "3     [112647, 14345, 129036, 190479, 159782, 176167...  \n",
       "4     [122882, 108565, 110620, 63533, 77871, 54, 778...  \n",
       "...                                                 ...  \n",
       "1995                                                 []  \n",
       "1996                                                 []  \n",
       "1997                                                 []  \n",
       "1998                                                 []  \n",
       "1999                                                 []  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user = pd.read_json(USER_DATA, lines=True)\n",
    "df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[42558, 65272, 13353]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[146057, 195688, 143652]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[67551, 85247, 33714]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[116097, 192703, 103229]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[68756, 140123, 135289]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>[95090, 131393, 130239]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>[2360, 147130, 8145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>[99794, 138694, 157888]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>[55561, 60372, 51442]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>[125409, 77906, 124792]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   history\n",
       "0           0     [42558, 65272, 13353]\n",
       "1           1  [146057, 195688, 143652]\n",
       "2           2     [67551, 85247, 33714]\n",
       "3           3  [116097, 192703, 103229]\n",
       "4           4   [68756, 140123, 135289]\n",
       "...       ...                       ...\n",
       "1995     1995   [95090, 131393, 130239]\n",
       "1996     1996      [2360, 147130, 8145]\n",
       "1997     1997   [99794, 138694, 157888]\n",
       "1998     1998     [55561, 60372, 51442]\n",
       "1999     1999   [125409, 77906, 124792]\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_user = pd.read_json('./dataset/origin_user_data.json', lines=True)\n",
    "origin_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2000):\n",
    "#     df_user['non_click'][i] = []\n",
    "# df_user.to_json(USER_DATA, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Data\n",
    "\n",
    "Both the training and testing environments share a common pool of **209527 items** as their item candidate pool. For the side information of these items, we provide text descriptions for each news article. The item dataset is derived from the [News Category Dataset](https://www.kaggle.com/datasets/rmisra/news-category-dataset). It's important to note that you should only use the dataset provided by us. Utilizing the original dataset, which contains extra information, will be considered as cheating. Let's explore the item dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209522</th>\n",
       "      <td>209522</td>\n",
       "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
       "      <td>Verizon Wireless and AT&amp;T are already promotin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209523</th>\n",
       "      <td>209523</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "      <td>Afterward, Azarenka, more effusive with the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209524</th>\n",
       "      <td>209524</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209525</th>\n",
       "      <td>209525</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "      <td>CORRECTION: An earlier version of this story i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209526</th>\n",
       "      <td>209526</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "      <td>The five-time all-star center tore into his te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209527 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id                                           headline  \\\n",
       "0             0  Over 4 Million Americans Roll Up Sleeves For O...   \n",
       "1             1  American Airlines Flyer Charged, Banned For Li...   \n",
       "2             2  23 Of The Funniest Tweets About Cats And Dogs ...   \n",
       "3             3  The Funniest Tweets From Parents This Week (Se...   \n",
       "4             4  Woman Who Called Cops On Black Bird-Watcher Lo...   \n",
       "...         ...                                                ...   \n",
       "209522   209522  RIM CEO Thorsten Heins' 'Significant' Plans Fo...   \n",
       "209523   209523  Maria Sharapova Stunned By Victoria Azarenka I...   \n",
       "209524   209524  Giants Over Patriots, Jets Over Colts Among  M...   \n",
       "209525   209525  Aldon Smith Arrested: 49ers Linebacker Busted ...   \n",
       "209526   209526  Dwight Howard Rips Teammates After Magic Loss ...   \n",
       "\n",
       "                                        short_description  \n",
       "0       Health experts said it is too early to predict...  \n",
       "1       He was subdued by passengers and crew when he ...  \n",
       "2       \"Until you have a dog you don't understand wha...  \n",
       "3       \"Accidentally put grown-up toothpaste on my to...  \n",
       "4       Amy Cooper accused investment firm Franklin Te...  \n",
       "...                                                   ...  \n",
       "209522  Verizon Wireless and AT&T are already promotin...  \n",
       "209523  Afterward, Azarenka, more effusive with the pr...  \n",
       "209524  Leading up to Super Bowl XLVI, the most talked...  \n",
       "209525  CORRECTION: An earlier version of this story i...  \n",
       "209526  The five-time all-star center tore into his te...  \n",
       "\n",
       "[209527 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item = pd.read_json(ITEM_DATA, lines=True)\n",
    "df_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# # Instantiate the SentenceTransformer model\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# # Compute embeddings for headlines\n",
    "# headline_embeddings = model.encode(df_item['headline'].to_list(), show_progress_bar=True)\n",
    "\n",
    "# # Compute embeddings for short descriptions\n",
    "# description_embeddings = model.encode(df_item['short_description'].to_list(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./dataset/headline_embeddings.npy', headline_embeddings)\n",
    "# np.save('./dataset/description_embeddings.npy', description_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline embedding shape: (209527, 384)\n",
      "description embeddings shape: (209527, 384)\n"
     ]
    }
   ],
   "source": [
    "headline_embeddings = np.load('./dataset/headline_embeddings.npy')\n",
    "description_embeddings = np.load('./dataset/description_embeddings.npy')\n",
    "print('Headline embedding shape:', headline_embeddings.shape)\n",
    "print('description embeddings shape:', description_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item embedding shape:  (209527, 384)\n"
     ]
    }
   ],
   "source": [
    "headline_weight = 2\n",
    "description_weight = 1\n",
    "item_embeddings = (headline_embeddings * headline_weight + description_embeddings * description_weight) / (headline_weight + description_weight)\n",
    "print('Item embedding shape: ',item_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Environments\n",
    "\n",
    "We offer two simulation environments in this competition: `TrainingEnvironment` and `TestingEnvironment`. The only distinction between the two environments is the number of users, with 1000 for training and 2000 for testing. All public methods for both environments behave the same since they share the same base class.\n",
    "\n",
    "**Important Note: Ensure that you collect interaction data only by accessing the environment through the designated public methods listed below. Directly accessing or modifying any file or code in the `evaluation` directory, or retrieving internal attributes and states of the environment (including all attributes / methods starting with an underscore `_`), will be considered as cheating.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Classes\n",
    "\n",
    "### <kbd>class</kbd> `TrainingEnvironment`\n",
    "Class for the training environment. Contains first 1000 users with user ID ranging from 0 to 999. \n",
    "\n",
    "### <kbd>class</kbd> `TestingEnvironment`\n",
    "Class for the testing environment. Contains all 2000 users with user ID ranging from 0 to 1999. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Public Methods\n",
    "\n",
    "**Note that both `TrainingEnvironment` and `TestingEnvironment` shares the same set of public methods.**\n",
    "\n",
    "---\n",
    "\n",
    "### <kbd>function</kbd> `reset`\n",
    "\n",
    "\n",
    "```python\n",
    "reset() → None\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Reset the environment to its initial parameters and states. \n",
    "\n",
    "---\n",
    "\n",
    "### <kbd>function</kbd> `has_next_state`\n",
    "\n",
    "\n",
    "```python\n",
    "has_next_state() → bool\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Verify whether the next state exists. The next state is considered to exist if there is at least one user still present in the environment. \n",
    "\n",
    "**Returns:**\n",
    "\n",
    "  - `True` if the next state exists, `False` otherwise. \n",
    "\n",
    "---\n",
    "\n",
    "### <kbd>function</kbd> `get_state`\n",
    "\n",
    "\n",
    "```python\n",
    "get_state() → int\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Get the current state (the user ID of the current user). \n",
    "\n",
    "**Returns:**\n",
    " \n",
    " - <b>``int``</b>:  The user ID of the current user, or `-1` if there are no active users in the environment. \n",
    "\n",
    "---\n",
    "\n",
    "### <kbd>function</kbd> `get_response`\n",
    "\n",
    "\n",
    "```python\n",
    "get_response(slate: list) → tuple[int, bool]\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Send the recommended slate (list of 5 distinct item IDs) and get the response from the current user. The internal user state will be updated according to the response, and a random user will be selected to be the next user (next state). \n",
    "\n",
    "**Args:**\n",
    " \n",
    " - <b>`slate`</b>:  `list[int]`  A list of 5 distinct item IDs to be recommended. \n",
    "\n",
    "**Returns:**\n",
    "\n",
    " - <b>`tuple[int, bool]`</b>:  The first entry indicates the `item ID` chosen by the user, or `-1` if the user decides not to choose any item.  The second entry represents whether the user is still in the environment after this interaction round. `True` if the user stays, `False` if the user leaves. \n",
    "\n",
    "**Raises:**\n",
    " \n",
    " - <b>``AssertionError``</b>:  If the slate length is not 5, contains duplicates or out-of-range item IDs, or if there are no active users in the environment. \n",
    "\n",
    "---\n",
    "\n",
    "### <kbd>function</kbd> `get_score`\n",
    "\n",
    "\n",
    "```python\n",
    "get_score() → list[float]\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Get the normalized session length score (0 ~ 1) for each user. \n",
    "\n",
    "**Returns:**\n",
    " \n",
    " - <b>``list[float]``</b>:  A list containing the normalized session length score for each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsRecommender(tf.Module):\n",
    "    def __init__(self, user_data, item_embeddings):\n",
    "        super(NewsRecommender, self).__init__()\n",
    "        self.item_embeddings = tf.Variable(item_embeddings)\n",
    "        self.item_bias = tf.Variable(np.zeros(item_embeddings.shape[0]), dtype=tf.float32)\n",
    "        self.user_embeddings = tf.Variable(self.initialize_user_embeddings(user_data, self.item_embeddings))\n",
    "        self.user_bias = tf.Variable(np.zeros(len(user_data)), dtype=tf.float32)\n",
    "\n",
    "    def initialize_user_embeddings(self, user_data, item_embeddings):\n",
    "        user_embeddings = []\n",
    "        for history in user_data['history']:\n",
    "            history_embeddings = tf.gather(item_embeddings, history)\n",
    "            user_embedding = tf.reduce_mean(history_embeddings, axis=0)\n",
    "            user_embeddings.append(user_embedding)\n",
    "    \n",
    "        return tf.stack(user_embeddings)\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, interact_sparse):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Get the dense user and item factors from the embedding matrices for the batch\n",
    "            user_embed = tf.nn.embedding_lookup(self.user_embeddings, interact_sparse.indices[:, 0])\n",
    "            item_embed = tf.nn.embedding_lookup(self.item_embeddings, interact_sparse.indices[:, 1])\n",
    "            user_b = tf.gather(self.user_bias, interact_sparse.indices[:, 0])\n",
    "            item_b = tf.gather(self.item_bias, interact_sparse.indices[:, 1])\n",
    "\n",
    "            # Compute the predictions\n",
    "            pred = tf.reduce_sum(user_embed * item_embed, axis=1) + user_b + item_b\n",
    "\n",
    "            # Compute the loss using binary cross-entropy\n",
    "            loss = tf.keras.losses.binary_crossentropy(interact_sparse.values, pred, from_logits=True)\n",
    "\n",
    "        # Get gradients\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "        # Apply gradients\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # @tf.function\n",
    "    def recommend(self, user_id, history):\n",
    "        # get user embedding\n",
    "        user_vector = tf.gather(self.user_embeddings, user_id)\n",
    "        user_b = tf.gather(self.user_bias, user_id)\n",
    "\n",
    "        # calculate the score between the user and all items embedding\n",
    "        scores = tf.reduce_sum(user_vector * self.item_embeddings, axis=1) + user_b + self.item_bias\n",
    "        scores = tf.reshape(scores, [-1])\n",
    "        \n",
    "        history_indices = tf.constant([[i] for i in history], dtype=tf.int64)\n",
    "        updates = tf.fill([len(history)], tf.float32.min)\n",
    "        scores = tf.tensor_scatter_nd_update(scores, history_indices, updates)\n",
    "                \n",
    "        # get top-5 score\n",
    "        _, top_indices = tf.math.top_k(scores, k=SLATE_SIZE)\n",
    "\n",
    "        return top_indices.numpy()\n",
    "    \n",
    "    # @tf.function\n",
    "    def update_response(self, user_ids, item_ids, isClick):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Get the dense user and item factors from the embedding matrices for the batch\n",
    "            user_embed = tf.nn.embedding_lookup(self.user_embeddings, user_ids)\n",
    "            item_embed = tf.nn.embedding_lookup(self.item_embeddings, item_ids)\n",
    "            user_b = tf.gather(self.user_bias, user_ids)\n",
    "            item_b = tf.gather(self.item_bias, item_ids)\n",
    "            \n",
    "            # Compute the predictions\n",
    "            logits = tf.reduce_sum(user_embed * item_embed, axis=1) + user_b + item_b\n",
    "            \n",
    "            pred = tf.sigmoid(logits)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = tf.maximum(0.0, 1 - pred) if isClick else pred\n",
    "        \n",
    "        # Get gradients\n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "        # Apply gradients\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = NewsRecommender(df_user, item_embeddings)\n",
    "checkpoint_dir = './checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x28b27c290d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restore\n",
    "checkpoint.restore('./checkpoints/ckpt-60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 59989, 184546,   8533, 150805, 163488])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.recommend(0, df_user['history'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The implementation of the recommender algorithm is left to you. If you're in need of ideas, you can refer to the [Recommender Systems Tutorial](https://nthu-datalab.github.io/ml/labs/recommender-systems-tutorial/recommender-systems-tutorial.html) notebook in Lecture 16. Here, we'll just provide some example use cases of the public methods.\n",
    "\n",
    "**Hint:** If you're looking for inspiration, consider starting by collecting interaction data from the environment using your initial recommender policy. Afterward, improve your model with this data, and iterate through this collect-then-train loop.\n",
    "\n",
    "**Important Note: Ensure that you save your model weights after training. You will need to load a set of model weights trained exclusively on the training environment at the beginning of each test episode.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_interaction_matrix(user_data, item_length):\n",
    "    indices = [] \n",
    "    values = []  \n",
    "\n",
    "    for user_id, user_history in enumerate(user_data['history']):\n",
    "        for item_id in user_history:\n",
    "            indices.append([user_id, item_id])\n",
    "            values.append(1)  # if click\n",
    "    \n",
    "    for user_id, user_non_click in enumerate(user_data['non_click']):\n",
    "        for item_id in user_non_click:\n",
    "            if([user_id, item_id] in indices): continue\n",
    "            indices.append([user_id, item_id])\n",
    "            values.append(0)\n",
    "\n",
    "    # init sparse matrix\n",
    "    interaction_matrix = tf.sparse.SparseTensor(indices, values, dense_shape=[len(user_data), item_length])\n",
    "\n",
    "    # order sparse matrix\n",
    "    interaction_matrix = tf.sparse.reorder(interaction_matrix)\n",
    "\n",
    "    return interaction_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Based On user data (Offline Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 10\n",
    "\n",
    "# # init interaction matrix\n",
    "# interaction_matrix = initialize_interaction_matrix(df_user, item_embeddings.shape[0])\n",
    "\n",
    "# # prepare datasets\n",
    "# dataset_train = tf.data.Dataset.from_tensor_slices(interaction_matrix)\n",
    "# dataset_train = dataset_train.batch(batch_size=BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# # train the model\n",
    "# train_losses = []\n",
    "\n",
    "# for epoch in range(1, EPOCHS + 1):\n",
    "#     train_loss = []\n",
    "#     print(f'Epoch {epoch}:')\n",
    "\n",
    "#     # training\n",
    "#     for data in tqdm(dataset_train, desc='Training'):\n",
    "#         loss = recommender.train_step(data)\n",
    "#         train_loss.append(loss.numpy())\n",
    "    \n",
    "#     # record losses\n",
    "#     avg_train_loss = np.mean(train_loss)\n",
    "#     train_losses.append(avg_train_loss)\n",
    "\n",
    "#     # print losses\n",
    "#     print(f'Epoch {epoch} train_loss: {avg_train_loss:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 10\n",
    "\n",
    "# # init interaction matrix\n",
    "# interaction_matrix = initialize_interaction_matrix(df_user, item_embeddings.shape[0])\n",
    "\n",
    "# # prepare datasets\n",
    "# dataset_train = tf.data.Dataset.from_tensor_slices(interaction_matrix)\n",
    "# dataset_train = dataset_train.batch(batch_size=BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# # train the model\n",
    "# train_losses = []\n",
    "\n",
    "# for epoch in range(1, EPOCHS + 1):\n",
    "#     train_loss = []\n",
    "#     print(f'Epoch {epoch}:')\n",
    "\n",
    "#     # training\n",
    "#     for data in tqdm(dataset_train, desc='Training'):\n",
    "#         loss = recommender.train_step(data)\n",
    "#         train_loss.append(loss.numpy())\n",
    "    \n",
    "#     # record losses\n",
    "#     avg_train_loss = np.mean(train_loss)\n",
    "#     train_losses.append(avg_train_loss)\n",
    "\n",
    "#     # print losses\n",
    "#     print(f'Epoch {epoch} train_loss: {avg_train_loss:.4f}\\n')\n",
    "\n",
    "\n",
    "# # Initialize the training environment\n",
    "# train_env = TrainingEnvironment()\n",
    "\n",
    "# # Reset the training environment (this can be useful when you have finished one episode of simulation and do not want to re-initialize a new environment)\n",
    "# train_env.reset()\n",
    "\n",
    "# new_clicks = []\n",
    "# non_clicks = []\n",
    "\n",
    "# while(1):\n",
    "#     # Check if there exist any active users in the environment\n",
    "#     env_has_next_state = train_env.has_next_state()\n",
    "#     # print(f'There is {\"still some\" if env_has_next_state else \"no\"} active users in the training environment.')\n",
    "#     if(not env_has_next_state): \n",
    "#         print('\\nThere is no active users in the training environment.')\n",
    "#         break\n",
    "    \n",
    "#     # Get the current user ID\n",
    "#     user_id = train_env.get_state()\n",
    "#     # print(f'The current user is user {user_id}.')\n",
    "\n",
    "#     # Get the response of recommending the slate to the current user\n",
    "#     slate = recommender.recommend(user_id, df_user['history'][user_id])\n",
    "#     # print(\"Recommend items:\", slate)\n",
    "#     clicked_id, in_environment = train_env.get_response(slate)\n",
    "#     print(f'The click result of recommending {slate} to user {user_id} is {f\"item {clicked_id}\" if clicked_id != -1 else f\"{clicked_id} (no click)\"}.')\n",
    "    \n",
    "#     if(clicked_id != -1):\n",
    "#         new_clicks.append((user_id, clicked_id))\n",
    "#     else:\n",
    "#         for item_id in slate:\n",
    "#             non_clicks.append((user_id, item_id))\n",
    "    \n",
    "#     # print(f'User {user_id} {\"is still in\" if in_environment else \"leaves\"} the environment.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"New Collect Information:\", len(new_clicks))\n",
    "# for user_id, item_id in new_clicks:\n",
    "#     history_set = set(df_user.loc[user_id, 'history'])\n",
    "#     history_set.add(item_id)\n",
    "#     df_user.at[user_id, 'history'] = list(history_set)\n",
    "\n",
    "# for user_id, item_id in non_clicks:\n",
    "#     non_click_set = set(df_user.loc[user_id, 'non_click'])\n",
    "#     non_click_set.add(item_id)\n",
    "#     df_user.at[user_id, 'non_click'] = list(non_click_set)\n",
    "\n",
    "# # save df_user back to json\n",
    "# df_user.to_json(USER_DATA, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Based On User Response (Online Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 54232it [50:52, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no active users in the training environment.\n",
      "New Collect Information: 42258\n",
      "Training Score: 0.027116\n",
      "Leatherboard Score: 0.972884\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 57404it [53:39, 17.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no active users in the training environment.\n",
      "New Collect Information: 45007\n",
      "Training Score: 0.028702\n",
      "Leatherboard Score: 0.971298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 59659it [56:04, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no active users in the training environment.\n",
      "New Collect Information: 47032\n",
      "Training Score: 0.029829499999999995\n",
      "Leatherboard Score: 0.9701705\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 61896it [57:46, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no active users in the training environment.\n",
      "New Collect Information: 48937\n",
      "Training Score: 0.030947999999999996\n",
      "Leatherboard Score: 0.969052\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 63597it [59:20, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no active users in the training environment.\n",
      "New Collect Information: 50446\n",
      "Training Score: 0.0317985\n",
      "Leatherboard Score: 0.9682015\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 67324it [1:02:31, 17.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no active users in the training environment.\n",
      "New Collect Information: 53728\n",
      "Training Score: 0.03366199999999999\n",
      "Leatherboard Score: 0.966338\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 68403it [1:03:39, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no active users in the training environment.\n",
      "New Collect Information: 54618\n",
      "Training Score: 0.034201499999999996\n",
      "Leatherboard Score: 0.9657985\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 68979it [1:04:09, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no active users in the training environment.\n",
      "New Collect Information: 55304\n",
      "Training Score: 0.0344895\n",
      "Leatherboard Score: 0.9655105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 72735it [1:07:53, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no active users in the training environment.\n",
      "New Collect Information: 58577\n",
      "Training Score: 0.03636749999999999\n",
      "Leatherboard Score: 0.9636325\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 74592it [1:09:39, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no active users in the training environment.\n",
      "New Collect Information: 60153\n",
      "Training Score: 0.03729599999999999\n",
      "Leatherboard Score: 0.962704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_ITERS = 10\n",
    "\n",
    "for i in range(N_ITERS):\n",
    "    clicked_history = {user_id: set(history) for user_id, history in enumerate(origin_user['history'])}\n",
    "    \n",
    "    # Initialize the training environment\n",
    "    train_env = TrainingEnvironment()\n",
    "\n",
    "    # Reset the training environment (this can be useful when you have finished one episode of simulation and do not want to re-initialize a new environment)\n",
    "    train_env.reset()\n",
    "\n",
    "    new_clicks = []\n",
    "    non_clicks = []\n",
    "\n",
    "    with tqdm(desc='Training') as pbar:\n",
    "        while(1):\n",
    "            # Check if there exist any active users in the environment\n",
    "            env_has_next_state = train_env.has_next_state()\n",
    "            # print(f'There is {\"still some\" if env_has_next_state else \"no\"} active users in the training environment.')\n",
    "            if(not env_has_next_state): \n",
    "                print('There is no active users in the training environment.')\n",
    "                break\n",
    "            \n",
    "            # Get the current user ID\n",
    "            user_id = train_env.get_state()\n",
    "            # print(f'The current user is user {user_id}.')\n",
    "\n",
    "            # Get the response of recommending the slate to the current user\n",
    "            slate = recommender.recommend(user_id, clicked_history[user_id])\n",
    "            # print(\"Recommend items:\", slate)\n",
    "            clicked_id, in_environment = train_env.get_response(slate)\n",
    "            # print(f'The click result of recommending {slate} to user {user_id} is {f\"item {clicked_id}\" if clicked_id != -1 else f\"{clicked_id} (no click)\"}.')\n",
    "            \n",
    "            if(clicked_id != -1):\n",
    "                new_clicks.append((user_id, clicked_id))\n",
    "                recommender.update_response([user_id], [clicked_id], True)\n",
    "                clicked_history[user_id].add(clicked_id)\n",
    "            else:\n",
    "                for item_id in slate:\n",
    "                    non_clicks.append((user_id, item_id))\n",
    "                user_ids = np.repeat(user_id, SLATE_SIZE).tolist()\n",
    "                recommender.update_response(user_ids, slate, False)\n",
    "                \n",
    "            pbar.update(1)\n",
    "            \n",
    "            # print(f'User {user_id} {\"is still in\" if in_environment else \"leaves\"} the environment.')\n",
    "\n",
    "    print(\"New Collect Information:\", len(new_clicks))\n",
    "    for user_id, item_id in new_clicks:\n",
    "        history_set = set(df_user.loc[user_id, 'history'])\n",
    "        history_set.add(item_id)\n",
    "        df_user.at[user_id, 'history'] = list(history_set)\n",
    "    \n",
    "    for user_id, item_id in non_clicks:\n",
    "        non_click_set = set(df_user.loc[user_id, 'non_click'])\n",
    "        non_click_set.add(item_id)\n",
    "        df_user.at[user_id, 'non_click'] = list(non_click_set)\n",
    "\n",
    "    # save df_user back to json\n",
    "    df_user.to_json(USER_DATA, orient='records', lines=True)\n",
    "    \n",
    "    # save model weights\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    train_score = train_env.get_score()\n",
    "    df_train_score = pd.DataFrame([[user_id, score] for user_id, score in enumerate(train_score)], columns=['user_id', 'avg_score'])\n",
    "    avg_score = df_train_score['avg_score'].mean()\n",
    "    print(\"Training Score:\", avg_score)\n",
    "    print(\"Leatherboard Score:\", 1 - avg_score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.0027400000000000002\n",
      "Leatherboard Score: 0.99726\n"
     ]
    }
   ],
   "source": [
    "# Get the normalized session length score of all users\n",
    "train_score = train_env.get_score()\n",
    "df_train_score = pd.DataFrame([[user_id, score] for user_id, score in enumerate(train_score)], columns=['user_id', 'avg_score'])\n",
    "avg_score = df_train_score['avg_score'].mean()\n",
    "print(\"Training Score:\", avg_score)\n",
    "print(\"Leatherboard Score:\", 1 - avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "While testing, you are allowed to update your model. However, please adhere to the following rules:\n",
    "\n",
    "1. Follow the testing template provided below. Modify only the sections marked as `[TODO]`. Additionally, please carefully follow the instructions specified in each `[TODO]` section. Modifying other sections or not adhering to the instructions is strictly forbidden.\n",
    "\n",
    "2. Limit model updates to one testing episode. During testing-time updates, follow these steps: (a) **Load your model weights** trained exclusively on the training environment. (b) Run the testing environment and update your model with the collected data **during the testing process**. (c) Obtain the score for this testing episode and **delete your model weights since they now contain some testing information**. **You should not save the model weights trained on the testing environment for another testing episode. Doing so will be regarded as cheating.**\n",
    "\n",
    "3. Due to the randomness in the user decision process, **run the testing process 5 times** and calculate the **average session length** for each user as the final score. This part has been covered for you.\n",
    "\n",
    "After completing the testing process, remember to submit the generated `output.csv` file to the [Kaggle competition](https://www.kaggle.com/t/b06e248a3827434f80c4fdc6009d5fe0).\n",
    "\n",
    "We will illustrate the testing process with a pure random recommender below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the testing environment\n",
    "test_env = TestingEnvironment()\n",
    "scores = []\n",
    "\n",
    "# The item_ids here is for the random recommender\n",
    "item_ids = [i for i in range(N_ITEMS)]\n",
    "\n",
    "# Repeat the testing process for 5 times\n",
    "for _ in range(TEST_EPISODES):\n",
    "    # [TODO] Load your model weights here (in the beginning of each testing episode)\n",
    "    # [TODO] Code for loading your model weights...\n",
    "    clicked_history = {user_id: set(history) for user_id, history in enumerate(origin_user['history'])}\n",
    "    checkpoint.restore('./checkpoints/ckpt-35')\n",
    "    \n",
    "\n",
    "    # Start the testing process\n",
    "    with tqdm(desc='Testing') as pbar:\n",
    "        # Run as long as there exist some active users\n",
    "        while test_env.has_next_state():\n",
    "            # Get the current user id\n",
    "            cur_user = test_env.get_state()\n",
    "\n",
    "            # [TODO] Employ your recommendation policy to generate a slate of 5 distinct items\n",
    "            # [TODO] Code for generating the recommended slate...\n",
    "            # Here we provide a simple random implementation\n",
    "            # slate = random.sample(item_ids, k=SLATE_SIZE)\n",
    "            slate = recommender.recommend(cur_user, clicked_history[cur_user])\n",
    "\n",
    "            # Get the response of the slate from the environment\n",
    "            clicked_id, in_environment = test_env.get_response(slate)\n",
    "\n",
    "            # [TODO] Update your model here (optional)\n",
    "            # [TODO] You can update your model at each step, or perform a batched update after some interval\n",
    "            # [TODO] Code for updating your model...\n",
    "            if(clicked_id != -1):\n",
    "                recommender.update_response([cur_user], [clicked_id], True)\n",
    "                clicked_history[cur_user].add(clicked_id)\n",
    "            else:\n",
    "                user_ids = np.repeat(cur_user, SLATE_SIZE).tolist()\n",
    "                recommender.update_response(user_ids, slate, False)\n",
    "\n",
    "            # Update the progress indicator\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Record the score of this testing episode\n",
    "    scores.append(test_env.get_score())\n",
    "\n",
    "    # Reset the testing environment\n",
    "    test_env.reset()\n",
    "\n",
    "    # [TODO] Delete or reset your model weights here (in the end of each testing episode)\n",
    "    # [TODO] Code for deleting your model weights...\n",
    "    checkpoint.restore('./checkpoints/ckpt-35')\n",
    "\n",
    "# Calculate the average scores \n",
    "avg_scores = [np.average(score) for score in zip(*scores)]\n",
    "\n",
    "# Generate a DataFrame to output the result in a .csv file\n",
    "df_result = pd.DataFrame([[user_id, avg_score] for user_id, avg_score in enumerate(avg_scores)], columns=['user_id', 'avg_score'])\n",
    "df_result.to_csv(OUTPUT_PATH, index=False)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Score: 0.037068599999999986\n",
      "Leatherboard Score: 0.9629314\n"
     ]
    }
   ],
   "source": [
    "result_csv = pd.read_csv('./output/output.csv')\n",
    "\n",
    "result = result_csv['avg_score']\n",
    "\n",
    "print('Testing Score:', np.mean(result))\n",
    "print('Leatherboard Score:', 1 - np.mean(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(result_csv['user_id'], result_csv['avg_score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "\n",
    "### Student ID and Name\n",
    "\n",
    "- 109062135 陳家輝\n",
    "- 109062335 王懷鴻\n",
    "- 109062108 陳寬宸\n",
    "\n",
    "### Model\n",
    "\n",
    "在本次Cup中，我們首先使用了pretrained好的Sentence Embedding對新聞的headline和description做處理，並將兩者的embedding進行加權平均，作為item embedding的初始值。隨後根據user data的history，對user點擊的相關item取出它們的embedding，再做平均作為user embedding的初始值。\n",
    "\n",
    "模型的選用上，我們首先嘗試了Tutorial中的FunkSVD，在訓練一小段時間後，忽然想到上課老師有提到BiasSVD僅僅加上了item和user的bias就可以取得重大的突破，隨後便稍微修改了一下code將模型變成BiasSVD。\n",
    "\n",
    "### Data Collection\n",
    "\n",
    "在對模型進行訓練幾十個epochs後，我們便會跑一次training environment，在與環境互動的過程中做data collection，其中若是有點擊的item，我們就將該item記錄在該user的history裡面，若是都沒有點擊，則將五個item記錄在該user的non_clicks裡面。等到一次training environment互動都結束，就將這些收集到的資訊寫回到json裡面做永久保存。\n",
    "\n",
    "隨後在做新的訓練時，我們會再初始化一次interaction matrix，將更新過的user_data.json重新讀出，對點擊過的history設為1，沒有點擊的non_clicks設為0，並且我們發現，有的時候user點過的item，在後續又被推薦時可能會出現不點擊的情況，意思就是同一個item可能會同時出現在history和non_clicks，此時我們的做法就是將同時出現的item認定為user會偏好的，只是可能看過了所以不會想再看一次，那麼在設值的時候會將其設為1。\n",
    "\n",
    "### Training\n",
    "\n",
    "在訓練上，我們有分為offline和online的learning方式。\n",
    "\n",
    "- Offline\n",
    "    \n",
    "    Offline learning是基於user_data，對interaction matrix進行幾十個epochs的訓練後，會執行一次training environment進行互動，並且在過程中做data collection。這樣跑完1 round後，對更新過的資料重新初始化interaction matrix，再做新的訓練。\n",
    "\n",
    "- Online\n",
    "\n",
    "    Online learning是基於在training environment互動時，對user做出的response進行更新。若user有點擊item，則對該user和該item的embeddings進行正向更新，而若user都沒有點擊任何item，則對該五個items對應到該user的embeddings進行負向更新。每互動一次就更新一次，並且僅對特定的user和item進行更新。\n",
    "\n",
    "- Hybrid\n",
    "\n",
    "    Offline的好處是訓練較快，較容易取得一定的成果，但缺點是需要收集到很多的資訊才可以支撐的起訓練，否則很容易overfitting。在初期訓練的時候，因為很常發生overfitting的情況，導致training enviroment的互動很快就結束，在data collection上獲得不了太多的新資訊。\n",
    "\n",
    "    Online的好處則是訓練比較穩定，因為是互動一次就更新一次，對於user的偏好不會太快就擬合，呈現一個比較平滑的訓練趨勢，所以在推薦的過程中往往比Offline可以在環境中待得更久。但是壞處就是收斂的速度很慢。\n",
    "\n",
    "    所以我們嘗試結合兩者進行Hybrid的訓練。首先基於interaction matrix做Offline訓練一定的epochs，使模型在目前的資訊上具有一定的表現，再進入training environment中進行Online的訓練，幫助模型較平滑的進行更新避免overfitting。在與環境互動結束後，同樣將收集到的資訊寫回json，並在下一次訓練時重新初始化interaction matrix，再重複Offline和Online的訓練。\n",
    "\n",
    "### Recommendation\n",
    "\n",
    "在推薦的過程中，我們發現有的時候user點擊過的item在後續重新被推薦時，該user又會不點擊了，我們猜測可能是因為看過的item再次被推薦時user不會想再看一次，所以我們修改了我們的推薦策略，讓其可以基於user點擊過的記錄，不再推薦已經點擊過的item，從而發掘更多user的偏好。我們在每一次訓練時會重新初始化user history為原始僅具有3個點擊記錄的data，而在互動的過程中不斷將點擊item給記錄下來，避免重複推薦。\n",
    "\n",
    "具體的做法就是在推薦時會預測該user對於所有item的評分，我們將那些點擊過的item的分數手動設成很低，讓其不會再被推薦。此一做法比起一開始只推薦預測評分高的item而不考慮重複性的方法來的好上很多，取得了很重大的突破。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "- Ranking of **private** leaderboard of the Kaggle competition. (80%)\n",
    "- Report. (20%)\n",
    "\n",
    "### How is the Score For Ranking Calculated:\n",
    "\n",
    "We will calculate the MAE (Mean Absolute Error) between your submitted `output.csv` and a \"ground-truth\" of all 1s. The lower the better.\n",
    "\n",
    "### Your Report Should Contain:\n",
    "\n",
    "- Models you have tried during the competition. Briefly describe the main idea of the model and the reason why you chose that model.\n",
    "- List the experiments you have done. For instance, data collecting, utilizing the user / item datasets, hyperparameters tuning, training process, and so on.\n",
    "- Discussions, lessons learned, or anything else worth mentioning.\n",
    "- **Ensure your report notebook contains your training and testing code. We will re-run your code if we find your score on Kaggle suspicious.**\n",
    "\n",
    "Please name your report as `DL_comp4_{Your Team name}_report.ipynb.` and submit your report to the eeclass system before the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You Can Do\n",
    "\n",
    "- Implement any recommender models.\n",
    "- Collect data through accessing the **public methods provided by the environments** (i.e. methods listed in the ***Environment Public Methods*** section) and train your model.\n",
    "- Use the provided user history data (`dataset/user_data.json`) and item text description data (`dataset/item_data.json`) as auxiliary data to aid your model training.\n",
    "- Update the model during one testing episode while **following the rules mentioned in the ***Testing*** section.**\n",
    "- You can use a pretrained text encoder if you need text embeddings for the item text descriptions. **(This is the only part you can use a pretrained model in this competition.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You CAN NOT Do\n",
    "\n",
    "- Use any dataset other than the provided ones. Using the original News Category Dataset is also prohibited.\n",
    "- Use any pretrained recommender models.\n",
    "- Plagiarize other teams' work.\n",
    "- Hack our simulation environments. Any attempt of accessing or modifying the data files in the `evaluation` directory, modifying the source code of the environments, accessing or modifying the private attributes and methods (i.e. methods and attributes not listed in the ***Environment Public Methods*** section), not following the rules in the ***Testing*** section, or any other forbidden actions mentioned in the previous section of the notebook will be regarded as cheating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition Timeline\n",
    "\n",
    "- 2024/01/08 (Mon): Competition launched.\n",
    "- 2024/01/15 (Mon) 08:00 (TW): Competition deadline.\n",
    "- 2024/01/16 (Tue) 12:00 (TW): Report deadline.\n",
    "- 2024/01/16 (Tue) 15:30 (TW): Top-3 teams sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Misra, Rishabh. \"News Category Dataset.\" arXiv preprint arXiv:2209.11429 (2022).\n",
    "2. Misra, Rishabh and Jigyasa Grover. \"Sculpting Data for ML: The first act of Machine Learning.\" ISBN 9798585463570 (2021)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

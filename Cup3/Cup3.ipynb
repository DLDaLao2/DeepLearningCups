{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import re\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 5427 vocabularies in total\n",
      "Word to id mapping, for example: flower -> 1\n",
      "Id to word mapping, for example: 1 -> flower\n",
      "Tokens: <PAD>: 5427; <RARE>: 5428\n"
     ]
    }
   ],
   "source": [
    "dictionary_path = './dictionary'\n",
    "vocab = np.load(dictionary_path + '/vocab.npy')\n",
    "print('there are {} vocabularies in total'.format(len(vocab)))\n",
    "\n",
    "word2Id_dict = dict(np.load(dictionary_path + '/word2Id.npy'))\n",
    "id2word_dict = dict(np.load(dictionary_path + '/id2Word.npy'))\n",
    "print('Word to id mapping, for example: %s -> %s' % ('flower', word2Id_dict['flower']))\n",
    "print('Id to word mapping, for example: %s -> %s' % ('1', id2word_dict['1']))\n",
    "print('Tokens: <PAD>: %s; <RARE>: %s' % (word2Id_dict['<PAD>'], word2Id_dict['<RARE>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the flower shown has yellow anther red pistil and bright red petals.\n",
      "['9', '1', '82', '5', '11', '70', '20', '31', '3', '29', '20', '2', '5427', '5427', '5427', '5427', '5427', '5427', '5427', '5427']\n"
     ]
    }
   ],
   "source": [
    "def sent2IdList(line, MAX_SEQ_LENGTH=20):\n",
    "    MAX_SEQ_LIMIT = MAX_SEQ_LENGTH\n",
    "    padding = 0\n",
    "    \n",
    "    # data preprocessing, remove all puntuation in the texts\n",
    "    prep_line = re.sub('[%s]' % re.escape(string.punctuation), ' ', line.rstrip())\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    # prep_line = prep_line.replace('-', ' ') # TODO: origin line\n",
    "    prep_line = prep_line.replace('_', ' ')\n",
    "    prep_line = prep_line.replace('  ', ' ')\n",
    "    prep_line = prep_line.replace('.', '')\n",
    "    # transfrom string to char sequence\n",
    "    tokens = prep_line.split(' ')\n",
    "    tokens = [\n",
    "        tokens[i] for i in range(len(tokens))\n",
    "        if tokens[i] != ' ' and tokens[i] != ''\n",
    "    ]\n",
    "    l = len(tokens)\n",
    "    padding = MAX_SEQ_LIMIT - l\n",
    "    \n",
    "    # make sure length of each text is equal to MAX_SEQ_LENGTH, and replace the less common word with <RARE> token\n",
    "    for i in range(padding):\n",
    "        tokens.append('<PAD>')\n",
    "    # transform char sequence to id sequence\n",
    "    line = [\n",
    "        word2Id_dict[tokens[k]]\n",
    "        if tokens[k] in word2Id_dict else word2Id_dict['<RARE>']\n",
    "        for k in range(len(tokens))\n",
    "    ]\n",
    "\n",
    "    return line\n",
    "\n",
    "text = \"the flower shown has yellow anther red pistil and bright red petals.\"\n",
    "print(text)\n",
    "print(sent2IdList(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7370 image in training data\n"
     ]
    }
   ],
   "source": [
    "data_path = './datasets/'\n",
    "df = pd.read_pickle(data_path + '/text2ImgData.pkl')\n",
    "num_training_sample = len(df)\n",
    "n_images_train = num_training_sample\n",
    "print('There are %d image in training data' % (n_images_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Captions</th>\n",
       "      <th>ImagePath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>[[9, 2, 17, 9, 1, 6, 14, 13, 18, 3, 41, 8, 11,...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>[[4, 1, 5, 12, 2, 3, 11, 31, 28, 68, 106, 132,...</td>\n",
       "      <td>./102flowers/image_06736.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6737</th>\n",
       "      <td>[[9, 2, 27, 4, 1, 6, 14, 7, 12, 19, 5427, 5427...</td>\n",
       "      <td>./102flowers/image_06737.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>[[9, 1, 5, 8, 54, 16, 38, 7, 12, 116, 325, 3, ...</td>\n",
       "      <td>./102flowers/image_06738.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>[[4, 12, 1, 5, 29, 11, 19, 7, 26, 70, 5427, 54...</td>\n",
       "      <td>./102flowers/image_06739.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Captions  \\\n",
       "ID                                                        \n",
       "6734  [[9, 2, 17, 9, 1, 6, 14, 13, 18, 3, 41, 8, 11,...   \n",
       "6736  [[4, 1, 5, 12, 2, 3, 11, 31, 28, 68, 106, 132,...   \n",
       "6737  [[9, 2, 27, 4, 1, 6, 14, 7, 12, 19, 5427, 5427...   \n",
       "6738  [[9, 1, 5, 8, 54, 16, 38, 7, 12, 116, 325, 3, ...   \n",
       "6739  [[4, 12, 1, 5, 29, 11, 19, 7, 26, 70, 5427, 54...   \n",
       "\n",
       "                         ImagePath  \n",
       "ID                                  \n",
       "6734  ./102flowers/image_06734.jpg  \n",
       "6736  ./102flowers/image_06736.jpg  \n",
       "6737  ./102flowers/image_06737.jpg  \n",
       "6738  ./102flowers/image_06738.jpg  \n",
       "6739  ./102flowers/image_06739.jpg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idList2Text(idList):\n",
    "    text = \"\"\n",
    "    for id in idList:\n",
    "        if(id == \"5427\"): break\n",
    "        elif(id == \"5428\"): text += \"[UNK] \"\n",
    "        else: text += id2word_dict[id] + ' '\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: the flower shown has yellow anther red pistil and bright red petals [UNK]\n",
      "Tokenized IDs: [101, 1996, 6546, 3491, 2038, 3756, 14405, 5886, 2417, 14255, 16643, 2140, 1998, 4408, 2417, 15829, 100, 102]\n",
      "Token length: 18\n",
      "Decoded Tokens: [CLS] the flower shown has yellow anther red pistil and bright red petals [UNK] [SEP]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "text = idList2Text(['9', '1', '82', '5', '11', '70', '20', '31', '3', '29', '20', '2', '5428', '5427', '5427', '5427', '5427', '5427', '5427', '5427'])\n",
    "tokens = tokenizer.encode(text, add_special_tokens=True, padding='longest')\n",
    "\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Tokenized IDs:\", tokens)\n",
    "print(\"Token length:\", len(tokens))\n",
    "print(\"Decoded Tokens:\", tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this competition, you have to generate image in size 64x64x3\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_CHANNEL = 3\n",
    "\n",
    "def training_data_generator(caption, image_path):\n",
    "    # load in the image according to image path\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize(img, size=[IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    img.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL])\n",
    "    #TODO: data augmentation and normalize value to [-1, 1]\n",
    "    img = (img * 2) - 1\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_brightness(img, max_delta=0.2)\n",
    "    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n",
    "    img = tf.image.random_saturation(img, lower=0.8, upper=1.2)\n",
    "    # img = tf.image.random_hue(img, max_delta=0.2)    \n",
    "    \n",
    "    return img, caption\n",
    "\n",
    "def dataset_generator(filenames, batch_size, data_generator):\n",
    "    df = pd.read_pickle(filenames)\n",
    "\n",
    "    captions = df['Captions'].values\n",
    "    image_path = df['ImagePath'].values\n",
    "    textCaptionList = []\n",
    "    # imagePathList = []\n",
    "\n",
    "    # TODO: only choose one of descriptions to train, total descriptions is 70504\n",
    "    for i in range(len(captions)):\n",
    "        # for j in range(len(captions[i])):\n",
    "        #     textCaptionList.append(idList2Text(captions[i][j]))\n",
    "        #     imagePathList.append(imagePaths[i])\n",
    "        textCaptionList.append(idList2Text(random.choice(captions[i])))\n",
    "\n",
    "    # imagePathList = np.asarray(imagePathList)\n",
    "\n",
    "    captionList = [tokenizer.encode(text, add_special_tokens=True) for text in textCaptionList]\n",
    "    max_token_length = max(len(tokens) for tokens in captionList)\n",
    "    paddedCaptionList = tf.keras.preprocessing.sequence.pad_sequences(captionList, padding='post', maxlen=max_token_length)\n",
    "    paddedCaptionList = np.asarray(paddedCaptionList).astype(int)\n",
    "\n",
    "    # check whether padded caption has same length\n",
    "    for pad_caption in paddedCaptionList:\n",
    "        if(len(pad_caption) != max_token_length): print(len(pad_caption))\n",
    "        \n",
    "    print(f\"Dataset size: {len(paddedCaptionList)}, Caption Length: {len(paddedCaptionList[0])}\")\n",
    "    # assume that each row of `features` corresponds to the same row as `labels`.\n",
    "    assert len(paddedCaptionList) == len(image_path)\n",
    "    assert paddedCaptionList.dtype == int\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((paddedCaptionList, image_path))\n",
    "    dataset = dataset.map(data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(len(paddedCaptionList)).batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # in this competition, you have to generate image in size 64x64x3\n",
    "# IMAGE_HEIGHT = 64\n",
    "# IMAGE_WIDTH = 64\n",
    "# IMAGE_CHANNEL = 3\n",
    "\n",
    "# def training_data_generator(caption, image_path):\n",
    "#     # load in the image according to image path\n",
    "#     img = tf.io.read_file(image_path)\n",
    "#     img = tf.image.decode_image(img, channels=3)\n",
    "#     img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "#     img.set_shape([None, None, 3])\n",
    "#     img = tf.image.resize(img, size=[IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "#     img.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL])\n",
    "#     #TODO: data augmentation and normalize value to [-1, 1]\n",
    "#     # img = (img / 255.0) * 2 - 1\n",
    "    \n",
    "#     caption = tf.cast(caption, tf.int32)\n",
    "    \n",
    "\n",
    "#     return img, caption\n",
    "\n",
    "# def dataset_generator(filenames, batch_size, data_generator):\n",
    "#     # load the training data into two NumPy arrays\n",
    "#     df = pd.read_pickle(filenames)\n",
    "#     captions = df['Captions'].values\n",
    "#     image_path = df['ImagePath'].values\n",
    "#     caption = []\n",
    "#     # image_path = []\n",
    "#     # each image has 1 to 10 corresponding captions\n",
    "#     # we choose one of them randomly for training\n",
    "#     for i in range(len(captions)):\n",
    "#         # for j in range(len(captions[i])):\n",
    "#         #     caption.append(captions[i][j])\n",
    "#         #     image_path.append(imagePaths[i])\n",
    "#         caption.append(random.choice(captions[i]))\n",
    "        \n",
    "#     caption = np.asarray(caption)\n",
    "#     caption = caption.astype(int)\n",
    "#     # image_path = np.asarray(image_path)\n",
    "    \n",
    "#     # assume that each row of `features` corresponds to the same row as `labels`.\n",
    "#     print(len(caption), len(image_path))\n",
    "#     assert caption.shape[0] == image_path.shape[0]\n",
    "    \n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((caption, image_path))\n",
    "#     dataset = dataset.map(data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#     dataset = dataset.shuffle(len(caption)).batch(batch_size, drop_remainder=True)\n",
    "#     dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "#     return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparas = {\n",
    "    'MAX_SEQ_LENGTH': 20,                     # maximum sequence length\n",
    "    'EMBED_DIM': 256,                         # word embedding dimension\n",
    "    'VOCAB_SIZE': len(word2Id_dict),          # size of dictionary of captions\n",
    "    'RNN_HIDDEN_SIZE': 128,                   # number of RNN neurons\n",
    "    'Z_DIM': 512,                             # random noise z dimension\n",
    "    'DENSE_DIM': 256,                         # number of neurons in dense layer\n",
    "    'IMAGE_SIZE': [64, 64, 3],                # render image size\n",
    "    'BATCH_SIZE': 64,\n",
    "    'LR': 2e-4,                               # TODO: origin LR is 1e-4\n",
    "    'LR_DECAY': 0.5,\n",
    "    'BETA_1': 0.5,\n",
    "    'N_EPOCH': 600,\n",
    "    'N_SAMPLE': num_training_sample,          # size of training data\n",
    "    'CHECKPOINTS_DIR': './checkpoints/demo',  # checkpoint path\n",
    "    'PRINT_FREQ': 10,                         # printing frequency of loss\n",
    "    'CRITIC': 5                               # the number of iterations of the critic per generator iteration\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 7370, Caption Length: 29\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_generator(data_path + '/text2ImgData.pkl', hparas['BATCH_SIZE'], training_data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  101  2023  6546  2038 15829  2008  2024  3756  1998  2200  2235   102\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0], shape=(29,), dtype=int32)\n",
      "[CLS] this flower has petals that are yellow and very small [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  101  2023  6546  2038  1037  2843  1997  3756 15829  2008  2298  2200\n",
      " 27036   102     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0], shape=(29,), dtype=int32)\n",
      "[CLS] this flower has a lot of yellow petals that look very fluffy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  101  2023  3492  2417  6546  2038  2317  1998  2417 15829  2006  1996\n",
      "  5955   102     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0], shape=(29,), dtype=int32)\n",
      "[CLS] this pretty red flower has white and red petals on the tip [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  101  2023  6546  2003  2317  1999  3609  1998  2038 15829  2008  2024\n",
      " 21766 28579  2039  1998  2852 29046   102     0     0     0     0     0\n",
      "     0     0     0     0     0], shape=(29,), dtype=int32)\n",
      "[CLS] this flower is white in color and has petals that are ruffled up and drooping [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.499497890472412\n"
     ]
    }
   ],
   "source": [
    "# Check result\n",
    "import time\n",
    "count = 0\n",
    "start_time = time.time()\n",
    "for idx, (image_batch, caption_batch) in enumerate(dataset):\n",
    "    for image, caption in zip(image_batch, caption_batch):\n",
    "        # print(caption.numpy().decode('utf-8'))\n",
    "        print(caption)\n",
    "        print(tokenizer.decode(caption))\n",
    "        image = np.clip(image.numpy(), 0, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        count += 1\n",
    "        break\n",
    "    if(count == 4): break\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TextEncoder(tf.keras.Model):\n",
    "#     \"\"\"\n",
    "#     Encode text (a caption) into hidden representation\n",
    "#     input: text, which is a list of ids\n",
    "#     output: embedding, or hidden representation of input text in dimension of RNN_HIDDEN_SIZE\n",
    "#     \"\"\"\n",
    "#     def __init__(self, hparas):\n",
    "#         super(TextEncoder, self).__init__()\n",
    "#         self.hparas = hparas\n",
    "#         self.batch_size = self.hparas['BATCH_SIZE']\n",
    "        \n",
    "#         # embedding with tensorflow API\n",
    "#         self.embedding = layers.Embedding(self.hparas['VOCAB_SIZE'], self.hparas['EMBED_DIM'])\n",
    "#         # RNN, here we use GRU cell, another common RNN cell similar to LSTM\n",
    "#         self.gru = layers.GRU(self.hparas['RNN_HIDDEN_SIZE'],\n",
    "#                               return_sequences=True,\n",
    "#                               return_state=True,\n",
    "#                               recurrent_initializer='glorot_uniform')\n",
    "    \n",
    "#     def call(self, text, hidden):\n",
    "#         text = self.embedding(text)\n",
    "#         output, state = self.gru(text, initial_state = hidden)\n",
    "#         return output[:, -1, :], state\n",
    "    \n",
    "#     def initialize_hidden_state(self):\n",
    "#         return tf.zeros((self.hparas['BATCH_SIZE'], self.hparas['RNN_HIDDEN_SIZE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel\n",
    "\n",
    "class TextEncoder(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Encode text (a caption) into hidden representation\n",
    "    input: text\n",
    "    output: embedding, or hidden representation of input text in dimension of RNN_HIDDEN_SIZE\n",
    "    \"\"\"\n",
    "    def __init__(self, hparas):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.hparas = hparas\n",
    "        self.batch_size = self.hparas['BATCH_SIZE']\n",
    "        self.bert = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def call(self, text_ids):\n",
    "        hidden = self.bert(text_ids)[0]\n",
    "\n",
    "        return hidden[:, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modify Generator, and DCGAN architecture is different from lab\n",
    "class Generator(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Generate fake image based on given text(hidden representation) and noise z\n",
    "    input: text and noise\n",
    "    output: fake image with size 64*64*3\n",
    "    \"\"\"\n",
    "    def __init__(self, hparas):\n",
    "        super(Generator, self).__init__()\n",
    "        self.hparas = hparas\n",
    "        # x-shape\n",
    "        img_shape = self.hparas['IMAGE_SIZE']\n",
    "        xh, xw, xc = img_shape\n",
    "        z_dim = self.hparas['Z_DIM']\n",
    "        # z-shape\n",
    "        zh = xh // 4 \n",
    "        zw = xw // 4\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.denseText = tf.keras.layers.Dense(units=self.hparas['DENSE_DIM'])\n",
    "        self.dense1 = tf.keras.layers.Dense(units=1024)\n",
    "        # self.dense1 = tf.keras.layers.Dense(units=4*4*512)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=zh*zw<<8)\n",
    "        self.convT1 = tf.keras.layers.Conv2DTranspose(\n",
    "            filters = 256,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\"\n",
    "        )\n",
    "        self.convT2 = tf.keras.layers.Conv2DTranspose(\n",
    "            filters = 128,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\"\n",
    "        )\n",
    "        self.convT3 = tf.keras.layers.Conv2DTranspose(\n",
    "            filters = 64,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\"\n",
    "        )\n",
    "        self.convT4 = tf.keras.layers.Conv2DTranspose(\n",
    "            filters = xc,\n",
    "            kernel_size = 5,\n",
    "            strides = 2,\n",
    "            padding = \"SAME\",\n",
    "            activation = keras.activations.tanh # TODO: origin sigmoid\n",
    "        )\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "        self.leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.2) # TODO: origin relu\n",
    "        self.reshape = tf.keras.layers.Reshape(target_shape=(zh, zw, 256))\n",
    "        # self.reshape = tf.keras.layers.Reshape(target_shape=(4, 4, 512))\n",
    "        \n",
    "    def call(self, text, noise_z):\n",
    "        text = self.flatten(text)\n",
    "        # text = self.denseText(text)\n",
    "        # text = self.leaky_relu(text)\n",
    "        \n",
    "        x = tf.concat([noise_z, text], axis=1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.reshape(x)\n",
    "        # x = self.convT1(x)\n",
    "        # x = self.bn2(x)\n",
    "        # x = self.leaky_relu(x)\n",
    "        # x = self.convT2(x)\n",
    "        # x = self.bn3(x)\n",
    "        # x = self.leaky_relu(x)\n",
    "        x = self.convT3(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.convT4(x)\n",
    "    \n",
    "        return None, x # TODO: origin return logits, but it seems useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator architeture is different from lab\n",
    "class Discriminator(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Differentiate the real and fake image\n",
    "    input: image and corresponding text\n",
    "    output: labels, the real image should be 1, while the fake should be 0\n",
    "    \"\"\"\n",
    "    def __init__(self, hparas):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.hparas = hparas\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.denseText = tf.keras.layers.Dense(units=self.hparas['DENSE_DIM'])\n",
    "        self.denseImage = tf.keras.layers.Dense(units=1024)\n",
    "        self.denseCombine = tf.keras.layers.Dense(units=128)\n",
    "        self.denseOut = tf.keras.layers.Dense(1)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters = 64,\n",
    "            kernel_size = 5,\n",
    "            strides = (2, 2),\n",
    "            padding = \"SAME\",\n",
    "            input_shape = self.hparas['IMAGE_SIZE'])\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters = 128,\n",
    "            kernel_size = 5,\n",
    "            strides = (2, 2),\n",
    "            padding = \"SAME\"\n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv2D(\n",
    "            filters = 256,\n",
    "            kernel_size = 5,\n",
    "            strides = (2, 2),\n",
    "            padding = \"SAME\"\n",
    "        )\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn5 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn6 = tf.keras.layers.BatchNormalization()\n",
    "        self.leaky_relu = tf.keras.layers.LeakyReLU()\n",
    "    \n",
    "    def call(self, img, text):\n",
    "        text = self.flatten(text)\n",
    "        text = self.denseText(text)\n",
    "        text = self.bn1(text) # TODO: origin no bn\n",
    "        text = self.leaky_relu(text)\n",
    "        \n",
    "        img = self.conv1(img)\n",
    "        img = self.bn2(img) # TODO: origin no bn\n",
    "        img = self.leaky_relu(img)\n",
    "        img = self.conv2(img)\n",
    "        img = self.bn3(img)\n",
    "        img = self.leaky_relu(img)\n",
    "        # img = self.conv3(img)\n",
    "        # img = self.bn4(img)\n",
    "        # img = self.leaky_relu(img)\n",
    "        img = self.flatten(img)\n",
    "        img = self.denseImage(img)\n",
    "        img = self.bn6(img)\n",
    "        img = self.leaky_relu(img)\n",
    "        \n",
    "        # concatenate image with paired text\n",
    "        img_text = tf.concat([img, text], axis=1)\n",
    "        # img_text = self.denseCombine(img_text)\n",
    "        logits = self.denseOut(img_text)\n",
    "        output = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        return logits, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "text_encoder = TextEncoder(hparas)\n",
    "generator = Generator(hparas)\n",
    "discriminator = Discriminator(hparas)\n",
    "\n",
    "text_encoder.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: modify loss function\n",
    "# Lambda = 10\n",
    "# def cal_gradient_penalty(real_images, fake_images, text_embed):\n",
    "#     episolon = tf.random.uniform(shape=[hparas['BATCH_SIZE'], 1, 1, 1], minval=0.0, maxval=1.0)\n",
    "#     interpolated = episolon * real_images + (1 - episolon) * fake_images\n",
    "\n",
    "#     with tf.GradientTape() as gt:\n",
    "#         gt.watch(interpolated)\n",
    "#         pred, _ = discriminator(interpolated, text_embed, training = True)\n",
    "\n",
    "#     gradient_c2 = gt.gradient(pred, interpolated)\n",
    "#     slopes = tf.sqrt(tf.reduce_sum(tf.square(gradient_c2), axis=[1, 2, 3]))\n",
    "#     gradient_penalty = tf.reduce_mean(tf.square(slopes - 1.0))\n",
    "    \n",
    "#     return gradient_penalty\n",
    "\n",
    "# # WGAN + GP\n",
    "# def discriminator_loss(real_logits, fake_logits, gp):\n",
    "#     real_loss = tf.reduce_mean(real_logits)\n",
    "#     fake_loss = tf.reduce_mean(fake_logits)\n",
    "#     total_loss = fake_loss - real_loss + Lambda * gp\n",
    "#     return total_loss\n",
    "\n",
    "# def generator_loss(fake_logits):\n",
    "#     return -tf.reduce_mean(fake_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_logits, fake_logits):\n",
    "    # output value of real image should be 1\n",
    "    real_loss = cross_entropy(tf.ones_like(real_logits), real_logits)\n",
    "    # output value of fake image should be 0\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_logits), fake_logits)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    # output value of fake image should be 0\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: WGAN origin optimizers: RMSProp\n",
    "generator_optimizer = keras.optimizers.Adam(hparas['LR'])\n",
    "discriminator_optimizer = keras.optimizers.SGD(hparas['LR'])\n",
    "# generator_optimizer = keras.optimizers.RMSprop(hparas['LR'])\n",
    "# discriminator_optimizer = keras.optimizers.RMSprop(hparas['LR'])\n",
    "\n",
    "# one benefit of tf.train.Checkpoint() API is we can save everything seperately\n",
    "checkpoint_dir = hparas['CHECKPOINTS_DIR']\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 text_encoder=text_encoder, # TODO: not sure about if we need to save bert weights\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "# def train_step(real_image, caption, hidden):\n",
    "#     # random noise for generator\n",
    "#     noise = tf.random.normal(shape=[hparas['BATCH_SIZE'], hparas['Z_DIM']], mean=0.0, stddev=1.0)\n",
    "    \n",
    "#     with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "#         text_embed, hidden = text_encoder(caption, hidden)\n",
    "#         _, fake_image = generator(text_embed, noise)\n",
    "#         real_logits, real_output = discriminator(real_image, text_embed)\n",
    "#         fake_logits, fake_output = discriminator(fake_image, text_embed)\n",
    "\n",
    "#         g_loss = generator_loss(fake_logits)\n",
    "#         d_loss = discriminator_loss(real_logits, fake_logits)\n",
    "\n",
    "#     grad_g = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "#     grad_d = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "\n",
    "#     generator_optimizer.apply_gradients(zip(grad_g, generator.trainable_variables))\n",
    "#     discriminator_optimizer.apply_gradients(zip(grad_d, discriminator.trainable_variables))\n",
    "    \n",
    "#     return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modify train step\n",
    "@tf.function\n",
    "def disc_train_step(real_image, caption):\n",
    "    # random noise for generator\n",
    "    noise = tf.random.normal(shape=[hparas['BATCH_SIZE'], hparas['Z_DIM']], mean=0.0, stddev=1.0)\n",
    "    \n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        text_embed = text_encoder(caption)\n",
    "        _, fake_image = generator(text_embed, noise, training=True)\n",
    "        real_logits, real_output = discriminator(real_image, text_embed, training=True)\n",
    "        fake_logits, fake_output = discriminator(fake_image, text_embed, training=True)\n",
    "    \n",
    "        # gp = cal_gradient_penalty(real_image, fake_image, text_embed)\n",
    "        g_loss = generator_loss(fake_logits)\n",
    "        d_loss = discriminator_loss(real_logits, fake_logits)\n",
    "        # d_loss = discriminator_loss(real_logits, fake_logits, gp)\n",
    "    \n",
    "    grad_d = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(grad_d, discriminator.trainable_variables))\n",
    "    \n",
    "    # clipping\n",
    "    # for v in discriminator.trainable_variables: \n",
    "    #     v.assign(tf.clip_by_value(v, -0.01, 0.01))\n",
    "    \n",
    "    return g_loss, d_loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def gen_train_step(real_image, caption):\n",
    "    # random noise for generator\n",
    "    noise = tf.random.normal(shape=[hparas['BATCH_SIZE'], hparas['Z_DIM']], mean=0.0, stddev=1.0)\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        text_embed = text_encoder(caption)\n",
    "        _, fake_image = generator(text_embed, noise, training=True)\n",
    "        real_logits, real_output = discriminator(real_image, text_embed, training=True)\n",
    "        fake_logits, fake_output = discriminator(fake_image, text_embed, training=True)\n",
    "    \n",
    "        # gp = cal_gradient_penalty(real_image, fake_image, text_embed)\n",
    "        g_loss = generator_loss(fake_logits)\n",
    "        d_loss = discriminator_loss(real_logits, fake_logits)\n",
    "        # d_loss = discriminator_loss(real_logits, fake_logits, gp)\n",
    "        \n",
    "    grad_g = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(grad_g, generator.trainable_variables))\n",
    "    \n",
    "    return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = []\n",
    "for i in range(hparas['CRITIC']):\n",
    "    Train.append(disc_train_step)\n",
    "Train.append(gen_train_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: delete hidden\n",
    "@tf.function\n",
    "def test_step(caption, noise):\n",
    "    text_embed = text_encoder(caption)\n",
    "    _, fake_image = generator(text_embed, noise)\n",
    "    return fake_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "    return img\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    # getting the pixel values between [0, 1] to save it\n",
    "    return plt.imsave(path, merge(images, size)*0.5 + 0.5)\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(images, size, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_generator(caption, batch_size):\n",
    "    caption = np.asarray(caption)\n",
    "    caption = caption.astype(int)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(caption)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this cell only work for batch_size = 64\n",
    "ni = int(np.ceil(np.sqrt(hparas['BATCH_SIZE'])))\n",
    "sample_size = hparas['BATCH_SIZE']\n",
    "sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, hparas['Z_DIM'])).astype(np.float32)\n",
    "sample_sentence = [\"the flower shown has yellow anther red pistil and bright red petals.\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower has petals that are yellow, white and purple and has dark lines\"] * int(sample_size/ni) + \\\n",
    "                  [\"the petals on this flower are white with a yellow center\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower has a lot of small round pink petals.\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower is orange in color, and has petals that are ruffled and rounded.\"] * int(sample_size/ni) + \\\n",
    "                  [\"the flower has yellow petals and the center of it is brown.\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower has petals that are blue and white.\"] * int(sample_size/ni) +\\\n",
    "                  [\"these white flowers have petals that start off white in color and end in a white towards the tips.\"] * int(sample_size/ni)\n",
    "\n",
    "for i, sent in enumerate(sample_sentence):\n",
    "    # sample_sentence[i] = sent2IdList(sent)\n",
    "    sample_sentence[i] = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "max_token_length = max(len(tokens) for tokens in sample_sentence)\n",
    "paddedCaptionList = tf.keras.preprocessing.sequence.pad_sequences(sample_sentence, padding='post', maxlen=max_token_length)\n",
    "paddedCaptionList = np.asarray(paddedCaptionList).astype(int)\n",
    "sample_sentence = sample_generator(paddedCaptionList, hparas['BATCH_SIZE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('samples/demo'):\n",
    "    os.makedirs('samples/demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modify train\n",
    "def train(dataset, epochs):\n",
    "    # hidden state of RNN\n",
    "    # hidden = text_encoder.initialize_hidden_state()\n",
    "    steps_per_epoch = int(hparas['N_SAMPLE']/hparas['BATCH_SIZE'])\n",
    "    \n",
    "    checkpoint_start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        g_total_loss = 0\n",
    "        d_total_loss = 0\n",
    "        start = time.time()\n",
    "        \n",
    "        count = 0\n",
    "        for image, caption in dataset:\n",
    "            # captions = [text.numpy().decode('utf-8') for text in caption]\n",
    "            # g_loss, d_loss = train_step(image, caption, hidden)\n",
    "            g_loss, d_loss = Train[count](image, caption)\n",
    "            g_total_loss += g_loss\n",
    "            d_total_loss += d_loss\n",
    "            if(count == hparas['CRITIC']): count = 0\n",
    "            else: count += 1\n",
    "            \n",
    "        time_tuple = time.localtime()\n",
    "        time_string = time.strftime(\"%m/%d/%Y, %H:%M:%S\", time_tuple)\n",
    "            \n",
    "        # if(epoch % 10 == 0):\n",
    "        print(\"Epoch {}, gen_loss: {:.4f}, disc_loss: {:.4f}\".format(epoch+1,\n",
    "                                                                    g_total_loss/steps_per_epoch,\n",
    "                                                                    d_total_loss/steps_per_epoch))\n",
    "        print('Time for epoch {} is {:.4f} sec'.format(epoch+1, time.time()-checkpoint_start_time))\n",
    "        checkpoint_start_time = time.time()\n",
    "        \n",
    "        # save the model\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        \n",
    "        # visualization\n",
    "        if (epoch + 1) % hparas['PRINT_FREQ'] == 0:\n",
    "            for caption in sample_sentence:\n",
    "                fake_image = test_step(caption, sample_seed)\n",
    "            save_images(fake_image, [ni, ni], 'samples/demo/train_{:02d}.jpg'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(dataset, hparas['N_EPOCH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
